{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Selfmade\n",
    "from KNN_Selfmade import KNN_Selfmade\n",
    "from Logistic_Regression_Selfmade import Logistic_Regression_Selfmade\n",
    "from Gaussian_Naive_Bayes_Selfmade import Gaussian_Naive_Bayes_Selfmade\n",
    "from CART_Selfmade import CART_Selfmade\n",
    "from SVM_Selfmade import SVC_Selfmade\n",
    "from ANN_Selfmade import ANN_Selfmade\n",
    "from KMeans_Cluster_Selfmade import KMeans_Selfmade\n",
    "from DBSCAN_Selfmade import DBSCAN_Selfmade\n",
    "from PCA_Selfmade import PCA_Selfmade\n",
    "from Ensemble_Bagging_Selfmade import Ensemble_Bagging_Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_df = pd.read_csv(\"../dataset/subsampled_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subsampled_df.drop(columns='deposit')\n",
    "y = subsampled_df['deposit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn_selfmade = KNN_Selfmade(neighbors=7, metric='euclidean')\n",
    "model_knn_selfmade.fit(X_train, y_train)\n",
    "y_pred_knn_selfmade = model_knn_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_knn_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       500\n",
      "           1       0.68      0.68      0.68       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.68      0.68      1000\n",
      "weighted avg       0.68      0.68      0.68      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_knn_selfmade = []\n",
    "all_pred_labels_knn_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_knn_selfmade = KNN_Selfmade(neighbors=7, metric='euclidean')\n",
    "    model_knn_selfmade.fit(X_train, y_train)\n",
    "    y_pred_knn_selfmade = model_knn_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_knn_selfmade.extend(y_test)\n",
    "    all_pred_labels_knn_selfmade.extend(y_pred_knn_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_knn_selfmade, all_pred_labels_knn_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66        96\n",
      "           1       0.69      0.72      0.70       104\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.69      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn_library = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
    "model_knn_library.fit(X_train, y_train)\n",
    "y_pred_knn_library = model_knn_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_knn_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_knn_selfmade == y_pred_knn_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Reg Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 6.669666868388253\n",
      "Iteration 200, Loss: 7.350000305793731\n",
      "Iteration 300, Loss: 7.368750305793454\n",
      "Iteration 400, Loss: 5.700000305828988\n",
      "Iteration 500, Loss: 7.443750305899775\n",
      "Iteration 600, Loss: 4.725000311649565\n",
      "Iteration 700, Loss: 7.012500305799562\n",
      "Iteration 800, Loss: 6.975000305800395\n",
      "Iteration 900, Loss: 4.762500305857858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.53      0.68       177\n",
      "           1       0.19      0.87      0.31        23\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.58      0.70      0.50       200\n",
      "weighted avg       0.88      0.57      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_selfmade = Logistic_Regression_Selfmade(learning_rate=0.5, n_iterations=1000, regularization='l2', lambda_param=0.01, loss_function='logit')\n",
    "model_log_reg_selfmade.fit(X_train, y_train)\n",
    "y_pred_log_reg_selfmade = model_log_reg_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_log_reg_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Reg K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 5.4684733407746595\n",
      "Iteration 200, Loss: 5.574270112202605\n",
      "Iteration 300, Loss: 5.212711401612636\n",
      "Iteration 400, Loss: 5.212500305834262\n",
      "Iteration 500, Loss: 5.081250305837038\n",
      "Iteration 600, Loss: 5.025000305838981\n",
      "Iteration 700, Loss: 4.8562503058428685\n",
      "Iteration 800, Loss: 4.987500305843978\n",
      "Iteration 900, Loss: 6.525000305808168\n",
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 7.443750305792066\n",
      "Iteration 200, Loss: 7.143750305796785\n",
      "Iteration 300, Loss: 4.950000305842035\n",
      "Iteration 400, Loss: 4.426419409335672\n",
      "Iteration 500, Loss: 6.543750305895335\n",
      "Iteration 600, Loss: 6.543750305895057\n",
      "Iteration 700, Loss: 6.337500305894503\n",
      "Iteration 800, Loss: 6.262500305893947\n",
      "Iteration 900, Loss: 6.150000305982212\n",
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 7.6312503059014425\n",
      "Iteration 200, Loss: 5.793750305882843\n",
      "Iteration 300, Loss: 6.900000305800949\n",
      "Iteration 400, Loss: 6.862500305801506\n",
      "Iteration 500, Loss: 6.600000305893946\n",
      "Iteration 600, Loss: 4.575000305851196\n",
      "Iteration 700, Loss: 4.518750305855082\n",
      "Iteration 800, Loss: 4.6503075131466565\n",
      "Iteration 900, Loss: 7.350000305899775\n",
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 5.850000305882843\n",
      "Iteration 200, Loss: 6.2625003058115\n",
      "Iteration 300, Loss: 4.358079497553311\n",
      "Iteration 400, Loss: 5.400000305833429\n",
      "Iteration 500, Loss: 6.862166902970638\n",
      "Iteration 600, Loss: 6.581250305805392\n",
      "Iteration 700, Loss: 6.506250305807057\n",
      "Iteration 800, Loss: 6.393750305809001\n",
      "Iteration 900, Loss: 6.393750305809278\n",
      "Iteration 0, Loss: 0.6931471805599452\n",
      "Iteration 100, Loss: 6.669666868388253\n",
      "Iteration 200, Loss: 7.350000305793731\n",
      "Iteration 300, Loss: 7.368750305793454\n",
      "Iteration 400, Loss: 5.700000305828988\n",
      "Iteration 500, Loss: 7.443750305899775\n",
      "Iteration 600, Loss: 4.725000311649565\n",
      "Iteration 700, Loss: 7.012500305799562\n",
      "Iteration 800, Loss: 6.975000305800395\n",
      "Iteration 900, Loss: 4.762500305857858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       500\n",
      "           1       0.57      0.63      0.60       500\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.58      0.57      0.57      1000\n",
      "weighted avg       0.58      0.57      0.57      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_log_reg_selfmade = []\n",
    "all_pred_labels_log_reg_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_log_reg_selfmade = Logistic_Regression_Selfmade(learning_rate=0.5, n_iterations=1000, regularization='l2', lambda_param=0.01, loss_function='cross_entropy')\n",
    "    model_log_reg_selfmade.fit(X_train, y_train)\n",
    "    y_pred_log_reg_selfmade = model_log_reg_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_log_reg_selfmade.extend(y_test)\n",
    "    all_pred_labels_log_reg_selfmade.extend(y_pred_log_reg_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_log_reg_selfmade, all_pred_labels_log_reg_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        22\n",
      "           1       0.83      0.83      0.83        18\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.85      0.85      0.85        40\n",
      "weighted avg       0.85      0.85      0.85        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_library = LogisticRegression(max_iter=100, C=1/0.1, penalty='l2')\n",
    "model_log_reg_library.fit(X_train, y_train)\n",
    "y_pred_log_reg_library = model_log_reg_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_log_reg_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_log_reg_selfmade == y_pred_log_reg_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79        31\n",
      "           1       0.44      0.89      0.59         9\n",
      "\n",
      "    accuracy                           0.72        40\n",
      "   macro avg       0.70      0.78      0.69        40\n",
      "weighted avg       0.84      0.72      0.75        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\EVELYN\\SEMESTER 4\\OHL\\GAIB\\GAIB2\\GAIB_SeleksiAsisten_bag2_bag3\\src\\Gaussian_Naive_Bayes_Selfmade.py:43: RuntimeWarning: divide by zero encountered in log\n",
      "  class_conditional = np.sum(np.log(self._pdf(idx, x)))\n"
     ]
    }
   ],
   "source": [
    "model_naive_bayes_selfmade = Gaussian_Naive_Bayes_Selfmade()\n",
    "model_naive_bayes_selfmade.fit(X_train, y_train)\n",
    "y_pred_naive_bayes_selfmade = model_naive_bayes_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_naive_bayes_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       500\n",
      "           1       0.80      0.67      0.73       500\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.76      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\EVELYN\\SEMESTER 4\\OHL\\GAIB\\GAIB2\\GAIB_SeleksiAsisten_bag2_bag3\\src\\Gaussian_Naive_Bayes_Selfmade.py:43: RuntimeWarning: divide by zero encountered in log\n",
      "  class_conditional = np.sum(np.log(self._pdf(idx, x)))\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_naive_bayes_selfmade = []\n",
    "all_pred_labels_naive_bayes_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_naive_bayes_selfmade = Gaussian_Naive_Bayes_Selfmade()\n",
    "    model_naive_bayes_selfmade.fit(X_train, y_train)\n",
    "    y_pred_naive_bayes_selfmade = model_naive_bayes_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_naive_bayes_selfmade.extend(y_test)\n",
    "    all_pred_labels_naive_bayes_selfmade.extend(y_pred_naive_bayes_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_naive_bayes_selfmade, all_pred_labels_naive_bayes_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83        26\n",
      "           1       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.79      0.81      0.79        40\n",
      "weighted avg       0.82      0.80      0.80        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_naive_bayes_library = GaussianNB()\n",
    "model_naive_bayes_library.fit(X_train, y_train)\n",
    "y_pred_naive_bayes_library = model_naive_bayes_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_naive_bayes_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_naive_bayes_selfmade == y_pred_naive_bayes_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.85      0.63        13\n",
      "           1       0.89      0.59      0.71        27\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.69      0.72      0.67        40\n",
      "weighted avg       0.76      0.68      0.68        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_CART_selfmade = CART_Selfmade(max_depth=3)\n",
    "model_CART_selfmade.fit(X_train, y_train)\n",
    "y_pred_CART_selfmade = model_CART_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_CART_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       500\n",
      "           1       0.73      0.79      0.75       500\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.75      0.74      0.74      1000\n",
      "weighted avg       0.75      0.74      0.74      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_CART_selfmade = []\n",
    "all_pred_labels_CART_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_CART_selfmade = CART_Selfmade(max_depth=3)\n",
    "    model_CART_selfmade.fit(X_train, y_train)\n",
    "    y_pred_CART_selfmade = model_CART_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_CART_selfmade.extend(y_test)\n",
    "    all_pred_labels_CART_selfmade.extend(y_pred_CART_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_CART_selfmade, all_pred_labels_CART_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.79      0.61        14\n",
      "           1       0.83      0.58      0.68        26\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.67      0.68      0.65        40\n",
      "weighted avg       0.72      0.65      0.66        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_CART_library = DecisionTreeClassifier(max_depth=3)\n",
    "model_CART_library.fit(X_train, y_train)\n",
    "y_pred_CART_library = model_CART_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_CART_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_CART_selfmade == y_pred_CART_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.53      0.65       159\n",
      "           1       0.25      0.61      0.35        41\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.54      0.57      0.50       200\n",
      "weighted avg       0.72      0.55      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SVC_selfmade = SVC_Selfmade(learning_rate=0.1, lambda_param=0.01, n_iterations=100, kernel='polynomial')\n",
    "model_SVC_selfmade.fit(X_train, y_train)\n",
    "y_pred_SVC_selfmade = model_SVC_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_SVC_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.84      0.64       500\n",
      "           1       0.55      0.19      0.29       500\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.53      0.52      0.46      1000\n",
      "weighted avg       0.53      0.52      0.46      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_SVC_selfmade = []\n",
    "all_pred_labels_SVC_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_SVC_selfmade = SVC_Selfmade(learning_rate=0.1, lambda_param=0.01, n_iterations=100, kernel='polynomial')\n",
    "    model_SVC_selfmade.fit(X_train, y_train)\n",
    "    y_pred_SVC_selfmade = model_SVC_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_SVC_selfmade.extend(y_test)\n",
    "    all_pred_labels_SVC_selfmade.extend(y_pred_SVC_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_SVC_selfmade, all_pred_labels_SVC_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.43      0.06         7\n",
      "           1       0.96      0.50      0.66       193\n",
      "\n",
      "    accuracy                           0.49       200\n",
      "   macro avg       0.49      0.46      0.36       200\n",
      "weighted avg       0.93      0.49      0.63       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_SVC_library = SVC(max_iter=100, kernel='poly')\n",
    "model_SVC_library.fit(X_train.values, y_train.values)\n",
    "y_pred_SVC_library = model_SVC_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_SVC_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_SVC_selfmade == y_pred_SVC_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.02s, train acc=0.50, train loss=18.74, test acc=0.50, test loss=0.75\n",
      "Epoch 2: 0.03s, train acc=0.50, train loss=18.69, test acc=0.50, test loss=0.75\n",
      "Epoch 3: 0.05s, train acc=0.50, train loss=18.69, test acc=0.50, test loss=0.75\n",
      "Epoch 4: 0.06s, train acc=0.50, train loss=18.65, test acc=0.50, test loss=0.75\n",
      "Epoch 5: 0.08s, train acc=0.50, train loss=18.69, test acc=0.50, test loss=0.75\n",
      "Epoch 6: 0.09s, train acc=0.50, train loss=18.69, test acc=0.50, test loss=0.74\n",
      "Epoch 7: 0.10s, train acc=0.50, train loss=18.61, test acc=0.50, test loss=0.74\n",
      "Epoch 8: 0.12s, train acc=0.50, train loss=18.61, test acc=0.50, test loss=0.74\n",
      "Epoch 9: 0.13s, train acc=0.50, train loss=18.61, test acc=0.50, test loss=0.74\n",
      "Epoch 10: 0.15s, train acc=0.50, train loss=18.65, test acc=0.50, test loss=0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.31      0.26        72\n",
      "           1       0.50      0.39      0.44       128\n",
      "\n",
      "    accuracy                           0.36       200\n",
      "   macro avg       0.36      0.35      0.35       200\n",
      "weighted avg       0.40      0.36      0.37       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ANN_selfmade = ANN_Selfmade(sizes=[51, 50, 1], activation='sigmoid')\n",
    "model_ANN_selfmade.train(X_train, y_train, X_test, y_test, batch_size=20, optimizer='sgd', l_rate=0.0001, beta=.9)\n",
    "y_pred_ANN_selfmade = model_ANN_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_ANN_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.01s, train acc=0.50, train loss=16.97, test acc=0.50, test loss=0.72\n",
      "Epoch 2: 0.03s, train acc=0.50, train loss=16.75, test acc=0.50, test loss=0.72\n",
      "Epoch 3: 0.04s, train acc=0.50, train loss=16.75, test acc=0.50, test loss=0.71\n",
      "Epoch 4: 0.05s, train acc=0.50, train loss=16.88, test acc=0.50, test loss=0.71\n",
      "Epoch 5: 0.06s, train acc=0.50, train loss=16.88, test acc=0.50, test loss=0.71\n",
      "Epoch 6: 0.08s, train acc=0.50, train loss=16.84, test acc=0.50, test loss=0.70\n",
      "Epoch 7: 0.09s, train acc=0.50, train loss=16.75, test acc=0.50, test loss=0.70\n",
      "Epoch 8: 0.10s, train acc=0.50, train loss=16.79, test acc=0.50, test loss=0.70\n",
      "Epoch 9: 0.12s, train acc=0.50, train loss=16.84, test acc=0.50, test loss=0.70\n",
      "Epoch 10: 0.13s, train acc=0.50, train loss=16.88, test acc=0.50, test loss=0.70\n",
      "Epoch 1: 0.01s, train acc=0.50, train loss=17.96, test acc=0.50, test loss=0.70\n",
      "Epoch 2: 0.03s, train acc=0.50, train loss=17.96, test acc=0.50, test loss=0.70\n",
      "Epoch 3: 0.04s, train acc=0.50, train loss=17.87, test acc=0.50, test loss=0.70\n",
      "Epoch 4: 0.06s, train acc=0.50, train loss=17.92, test acc=0.50, test loss=0.70\n",
      "Epoch 5: 0.06s, train acc=0.50, train loss=17.92, test acc=0.50, test loss=0.70\n",
      "Epoch 6: 0.08s, train acc=0.50, train loss=17.83, test acc=0.50, test loss=0.70\n",
      "Epoch 7: 0.09s, train acc=0.50, train loss=17.83, test acc=0.50, test loss=0.70\n",
      "Epoch 8: 0.10s, train acc=0.50, train loss=17.79, test acc=0.50, test loss=0.70\n",
      "Epoch 9: 0.12s, train acc=0.50, train loss=17.74, test acc=0.50, test loss=0.70\n",
      "Epoch 10: 0.14s, train acc=0.50, train loss=17.70, test acc=0.50, test loss=0.70\n",
      "Epoch 1: 0.02s, train acc=0.51, train loss=16.97, test acc=0.48, test loss=0.71\n",
      "Epoch 2: 0.04s, train acc=0.51, train loss=16.92, test acc=0.48, test loss=0.71\n",
      "Epoch 3: 0.05s, train acc=0.50, train loss=17.53, test acc=0.48, test loss=0.71\n",
      "Epoch 4: 0.07s, train acc=0.50, train loss=17.44, test acc=0.48, test loss=0.71\n",
      "Epoch 5: 0.08s, train acc=0.50, train loss=17.53, test acc=0.48, test loss=0.71\n",
      "Epoch 6: 0.10s, train acc=0.50, train loss=17.40, test acc=0.48, test loss=0.71\n",
      "Epoch 7: 0.11s, train acc=0.50, train loss=17.40, test acc=0.48, test loss=0.71\n",
      "Epoch 8: 0.13s, train acc=0.50, train loss=17.23, test acc=0.48, test loss=0.71\n",
      "Epoch 9: 0.14s, train acc=0.50, train loss=17.27, test acc=0.48, test loss=0.71\n",
      "Epoch 10: 0.16s, train acc=0.50, train loss=16.88, test acc=0.48, test loss=0.71\n",
      "Epoch 1: 0.01s, train acc=0.50, train loss=17.92, test acc=0.50, test loss=0.71\n",
      "Epoch 2: 0.03s, train acc=0.50, train loss=17.83, test acc=0.50, test loss=0.70\n",
      "Epoch 3: 0.05s, train acc=0.50, train loss=17.44, test acc=0.50, test loss=0.70\n",
      "Epoch 4: 0.06s, train acc=0.50, train loss=17.40, test acc=0.50, test loss=0.70\n",
      "Epoch 5: 0.07s, train acc=0.50, train loss=17.40, test acc=0.50, test loss=0.70\n",
      "Epoch 6: 0.08s, train acc=0.50, train loss=17.36, test acc=0.50, test loss=0.70\n",
      "Epoch 7: 0.10s, train acc=0.50, train loss=17.66, test acc=0.50, test loss=0.70\n",
      "Epoch 8: 0.11s, train acc=0.50, train loss=17.62, test acc=0.50, test loss=0.70\n",
      "Epoch 9: 0.13s, train acc=0.50, train loss=17.40, test acc=0.50, test loss=0.70\n",
      "Epoch 10: 0.14s, train acc=0.50, train loss=17.40, test acc=0.50, test loss=0.69\n",
      "Epoch 1: 0.01s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.78\n",
      "Epoch 2: 0.02s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.78\n",
      "Epoch 3: 0.03s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.77\n",
      "Epoch 4: 0.05s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.77\n",
      "Epoch 5: 0.06s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.77\n",
      "Epoch 6: 0.08s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.76\n",
      "Epoch 7: 0.09s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.76\n",
      "Epoch 8: 0.10s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.76\n",
      "Epoch 9: 0.12s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.76\n",
      "Epoch 10: 0.13s, train acc=0.49, train loss=17.44, test acc=0.52, test loss=0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.26      0.35       500\n",
      "           1       0.51      0.76      0.61       500\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.51      0.51      0.48      1000\n",
      "weighted avg       0.51      0.51      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true_labels_ANN_selfmade = []\n",
    "all_pred_labels_ANN_selfmade = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_ANN_selfmade = ANN_Selfmade(sizes=[51, 50, 1], activation='sigmoid')\n",
    "    model_ANN_selfmade.train(X_train, y_train, X_test, y_test, batch_size=20, optimizer='sgd', l_rate=0.0001, beta=.9)\n",
    "    y_pred_ANN_selfmade = model_ANN_selfmade.predict(X_test)\n",
    "    \n",
    "    all_true_labels_ANN_selfmade.extend(y_test)\n",
    "    all_pred_labels_ANN_selfmade.extend(y_pred_ANN_selfmade)\n",
    "\n",
    "print(classification_report(all_true_labels_ANN_selfmade, all_pred_labels_ANN_selfmade))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        22\n",
      "           1       0.56      0.56      0.56        18\n",
      "\n",
      "    accuracy                           0.60        40\n",
      "   macro avg       0.60      0.60      0.60        40\n",
      "weighted avg       0.60      0.60      0.60        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ANN_library = MLPClassifier(hidden_layer_sizes=(50,), activation='logistic', solver='sgd',\n",
    "                    learning_rate_init=0.0001, max_iter=10, batch_size=20, momentum=0.9)\n",
    "model_ANN_library.fit(X_train, y_train)\n",
    "y_pred_ANN_library = model_ANN_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_ANN_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrik yang digunakan: \n",
    "- precision: untuk mengetes kelas positif;\n",
    "- recall: untuk mengetes semua sampel yang benar-benar positif;\n",
    "- F1 score: gabungan precision dan recall. <br>\n",
    "Namun jika hanya boleh memilih 1 metrik saja, saya akan menggunakan F1 score karena F1 score sudah mencakup precision dan recall dan prediksi deposit ini tidak akan berakibat fatal sampai menyebabkan korban jiwa. Selain itu, F1 score juga dapat menjaga keseimbangan antara false positive dan false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "model_KMeans_selfmade = KMeans_Selfmade(n_clusters=2, max_iter=100)\n",
    "model_KMeans_selfmade.fit(X_train)\n",
    "y_pred_KMeans_selfmade = model_KMeans_selfmade.predict(X_test)\n",
    "\n",
    "print(y_pred_KMeans_selfmade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "model_KMeans_library = KMeans(n_clusters=2, max_iter=100)\n",
    "model_KMeans_library.fit(X_train)\n",
    "y_pred_KMeans_library = model_KMeans_library.predict(X_test)\n",
    "\n",
    "print(y_pred_KMeans_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.06      0.10        35\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.05        40\n",
      "   macro avg       0.14      0.03      0.05        40\n",
      "weighted avg       0.25      0.05      0.08        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_KMeans_library, y_pred_KMeans_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Selfmade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  4  4 -1  7  6  1  1  4  7  8  7 -1  1  1  1  0  6\n",
      "  9  1  1  1  6 -1  1 10  9 11 -1 -1  1 21  1  7  1  2 11 10 -1  5  3  0\n",
      "  7  4  8 12  1  1 13 20 -1  7  1  3  0  5 14  2 14  4  2  7 13  7  9  8\n",
      " -1  2  1  7 12  1  7 -1 15  6 21  1  4 -1  2 -1  5 16 17 18 -1  4  6 19\n",
      "  8  9 17 17  7  8  0  1 20  4 13 15 -1 -1  7  1  1  9  1  1 -1 21 -1  2\n",
      "  0  7  1 -1  1 13  5  8 15 16  0 11  4  7  8 22  3 23  2  1  5  5  1 11\n",
      "  7 14  7  1  4 15 -1  2  0 -1 17  7  4  7 -1  0]\n"
     ]
    }
   ],
   "source": [
    "model_DBSCAN_selfmade = DBSCAN_Selfmade(eps=200, min_samples=3, metric='euclidean', p=5)\n",
    "model_DBSCAN_selfmade.fit(X_train)\n",
    "y_pred_DBSCAN_selfmade = model_DBSCAN_selfmade.predict()\n",
    "\n",
    "print(y_pred_DBSCAN_selfmade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0\n",
      "  0  0  0  0  0  2  0  0  0  0 -1 -1  0  3  0  0  0  0  0  0 -1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0\n",
      "  1  0  0  0  0  0  0 -1  0  0  3  0  0 -1  0 -1  0  0  2  0  0  0  0  0\n",
      "  0  0  2  2  0  0  0  0  0  0  0  0 -1 -1  0  0  0  0  0  0 -1  3 -1  0\n",
      "  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  0  0 -1  0  0 -1  2  0  0  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "model_DBSCAN_library = DBSCAN(eps=200, min_samples=3).fit(X_train)\n",
    "y_pred_DBSCAN_library = model_DBSCAN_library.labels_\n",
    "\n",
    "print(y_pred_DBSCAN_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      1.00      0.89        16\n",
      "           0       1.00      0.07      0.13       132\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.16       160\n",
      "   macro avg       0.07      0.04      0.04       160\n",
      "weighted avg       0.91      0.16      0.19       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_DBSCAN_library, y_pred_DBSCAN_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data:\n",
      " [[-2.97320017e+00 -2.81347529e-01]\n",
      " [ 8.67671742e-01  1.56627551e+00]\n",
      " [-4.46660518e-01  1.81989737e+00]\n",
      " [ 1.78344417e+00  1.53863085e+00]\n",
      " [ 2.17997923e+00  2.40002453e+00]\n",
      " [-2.92151341e+00  1.46653275e+00]\n",
      " [-3.02988824e-01  7.57628035e-01]\n",
      " [ 1.50100516e+00  2.24523955e+00]\n",
      " [ 3.21840006e+00  1.79756988e+00]\n",
      " [-1.54942956e+00 -2.25314145e+00]\n",
      " [ 2.27899982e+00  2.57726159e+00]\n",
      " [ 1.25155021e+00  3.94493471e-01]\n",
      " [-8.71547634e-01  1.76393695e-01]\n",
      " [-7.27236255e-01  1.02551361e+00]\n",
      " [-1.19623477e+00  2.23679127e-01]\n",
      " [ 5.38284119e-01  2.96737926e+00]\n",
      " [ 1.83089244e-02  2.41307974e+00]\n",
      " [ 1.76732763e+00 -1.27513093e+00]\n",
      " [ 3.28725137e+00  1.19769700e-01]\n",
      " [-1.37544608e+00  1.36272537e+00]\n",
      " [ 1.38122975e+00  2.21575164e+00]\n",
      " [ 6.65684362e-01  1.85613640e+00]\n",
      " [-2.18009973e+00 -1.34418100e+00]\n",
      " [-5.66611334e-01  2.18986896e+00]\n",
      " [-2.94133630e+00 -7.73986164e-02]\n",
      " [ 2.12978152e+00  1.64595069e+00]\n",
      " [ 4.16526699e+00 -8.39723087e-01]\n",
      " [ 2.58950376e+00 -1.82392320e+00]\n",
      " [ 3.18800669e+00 -1.91629717e+00]\n",
      " [ 3.21374486e+00 -1.98225444e+00]\n",
      " [-1.02788856e+00  1.57869545e+00]\n",
      " [-1.50750363e+00  2.55415171e-01]\n",
      " [-3.56864469e+00  1.62670604e+00]\n",
      " [-1.11055631e+00  3.22032171e-02]\n",
      " [-3.83190104e+00 -1.68833985e+00]\n",
      " [-1.79406530e+00 -1.63074620e+00]\n",
      " [-1.52391019e+00  2.38105683e+00]\n",
      " [ 1.36852778e-01  2.71293121e+00]\n",
      " [ 1.96379998e+00 -2.08477186e-01]\n",
      " [ 4.19534485e-01  2.67079168e+00]\n",
      " [ 3.91299394e+00 -1.25456416e+00]\n",
      " [-5.75958697e-01  1.18460163e+00]\n",
      " [ 1.01770008e+00 -6.52288920e-01]\n",
      " [-4.18701192e+00  4.27218312e-01]\n",
      " [ 8.65150672e-01  1.06435233e+00]\n",
      " [-6.60345745e-02 -3.17797178e+00]\n",
      " [-1.61752833e+00  2.29601493e+00]\n",
      " [-5.68153275e-01 -4.57108257e+00]\n",
      " [-8.18541184e-01 -7.77617320e-01]\n",
      " [ 1.99099199e+00  8.50760858e-01]\n",
      " [-1.88235315e+00  1.02671354e-01]\n",
      " [ 1.72490970e+00  1.49439129e+00]\n",
      " [-4.33025299e-01  9.33538051e-01]\n",
      " [ 3.08853875e+00 -2.27754939e-01]\n",
      " [-2.30002837e+00  1.99814708e-01]\n",
      " [-7.98335320e-01  7.28326537e-02]\n",
      " [ 1.40467023e+00  7.01689017e-01]\n",
      " [ 1.73345848e+00 -1.33494073e+00]\n",
      " [ 7.73392134e-01 -4.84142635e-01]\n",
      " [-1.43808891e+00 -3.10569039e+00]\n",
      " [-4.29013569e+00 -1.27339708e+00]\n",
      " [ 2.48922851e+00 -1.46712890e+00]\n",
      " [-1.52485178e-01  2.38288769e+00]\n",
      " [ 3.06239012e+00 -2.05667642e+00]\n",
      " [-6.01888974e-01  1.64244137e+00]\n",
      " [ 2.46300167e+00 -1.55316894e+00]\n",
      " [ 2.63104582e-01  5.88769772e-01]\n",
      " [ 1.97757386e+00 -1.23491899e+00]\n",
      " [-1.77744452e+00  1.25180497e+00]\n",
      " [ 1.11914754e+00  2.18308080e+00]\n",
      " [ 2.19387263e-01  3.22060764e+00]\n",
      " [ 8.06450118e-01  8.93019699e-01]\n",
      " [-1.95762702e+00  2.25506694e+00]\n",
      " [ 1.28460859e+00  4.89037671e-01]\n",
      " [ 3.11549362e-01  2.45747160e+00]\n",
      " [ 2.18072075e-01 -5.85074196e-03]\n",
      " [-1.10115295e+00  3.01308199e+00]\n",
      " [-1.09993423e+00  7.77277485e-01]\n",
      " [-5.02760469e-01 -2.71989034e+00]\n",
      " [-3.53049612e+00  3.34338513e-01]\n",
      " [ 1.17618443e+00 -1.92406387e+00]\n",
      " [-1.14744670e+00 -1.12718466e+00]\n",
      " [ 1.77451197e+00  3.38655974e-01]\n",
      " [-1.18384443e+00  4.61268157e-01]\n",
      " [-3.82212005e-01  2.53914676e+00]\n",
      " [ 1.39746430e+00 -2.07213428e-01]\n",
      " [ 5.72397786e-01  1.60357498e+00]\n",
      " [-3.98947536e+00 -7.74287426e+00]\n",
      " [ 3.18583535e+00  4.98236806e-01]\n",
      " [ 1.58258369e+00 -1.95052719e+00]\n",
      " [ 8.21233032e-01 -3.17932934e+00]\n",
      " [ 5.52737702e-01 -3.67597756e+00]\n",
      " [-3.33787301e-02 -4.33549260e+00]\n",
      " [ 2.73763711e-01  7.23134595e-01]\n",
      " [-2.93608021e+00  6.10982721e-02]\n",
      " [ 3.18113732e-01 -2.67740586e+00]\n",
      " [ 1.77570250e+00 -1.33856214e+00]\n",
      " [-1.81191705e+00  2.15358591e+00]\n",
      " [ 1.73946022e+00  8.89290717e-01]\n",
      " [-1.74233972e+00  2.38398265e+00]\n",
      " [ 3.48100489e+00 -1.88139461e+00]\n",
      " [-1.41620073e+00 -5.99970037e-02]\n",
      " [-2.63943216e+00 -4.60891334e-01]\n",
      " [ 2.88037153e+00  7.47862223e-01]\n",
      " [ 2.03233177e+00  2.81932144e+00]\n",
      " [-1.19242143e+00  2.29792619e+00]\n",
      " [-3.50188197e+00  1.47567118e+00]\n",
      " [ 1.36320006e+00  1.73235649e+00]\n",
      " [-1.59121413e+00 -4.46059428e+00]\n",
      " [-1.51613225e-01 -3.18043001e+00]\n",
      " [-1.97984163e+00  1.14539107e+00]\n",
      " [ 4.07279286e+00 -7.65473993e-01]\n",
      " [ 3.22131774e+00 -1.40809613e+00]\n",
      " [-3.10852073e+00  8.96882795e-03]\n",
      " [-5.11775782e-01 -8.51675944e-01]\n",
      " [ 3.77378553e+00 -1.45971747e+00]\n",
      " [ 2.85014410e+00 -9.36910962e-01]\n",
      " [ 2.47730359e+00  1.62318143e+00]\n",
      " [-2.43164179e+00 -2.16934405e+00]\n",
      " [ 5.48295573e-01 -1.05972865e+00]\n",
      " [-2.74888940e+00 -3.06469692e+00]\n",
      " [-6.42507179e-01  1.19163581e+00]\n",
      " [ 3.55149930e+00 -1.83142527e+00]\n",
      " [-5.30434953e-01 -1.65274909e-01]\n",
      " [ 4.00356021e+00 -1.68822240e+00]\n",
      " [-2.64228004e+00 -1.29427272e+00]\n",
      " [-3.24692593e-01  4.80064497e-02]\n",
      " [-1.77904209e-01 -3.17508135e-02]\n",
      " [ 2.79621512e+00 -2.26417556e+00]\n",
      " [ 2.44532160e-01  2.74302581e-01]\n",
      " [-2.50834959e+00  7.47215106e-01]\n",
      " [-7.55009903e-01  2.23325255e+00]\n",
      " [-2.45346231e+00  2.26079137e-01]\n",
      " [-2.42814027e+00 -8.87213203e-01]\n",
      " [-2.41525313e+00  1.24452039e-02]\n",
      " [ 1.03762198e+00 -2.03743805e+00]\n",
      " [-1.67444861e+00  6.30124373e-01]\n",
      " [-2.29705773e+00 -9.95093306e-01]\n",
      " [ 2.05042284e+00 -1.40117715e+00]\n",
      " [ 8.92257616e-01  2.86004942e+00]\n",
      " [ 1.34602212e+00  7.29850736e-01]\n",
      " [-1.89418411e+00  1.72947936e+00]\n",
      " [ 2.65377283e+00 -1.10752171e+00]\n",
      " [ 7.32186774e-01  1.33390267e+00]\n",
      " [-7.53177570e-02  8.16975180e-01]\n",
      " [-9.90477200e-01  7.12119937e-01]\n",
      " [-1.56216402e+00 -2.70464528e-01]\n",
      " [ 1.21849859e-01  3.04384048e+00]\n",
      " [ 2.89919430e+00  2.57081725e-01]\n",
      " [-3.75525780e+00 -7.87359266e-01]\n",
      " [-1.85336307e+00 -1.19060255e-01]\n",
      " [-2.28859420e+00  3.18168918e-02]\n",
      " [-8.76012971e-01 -1.78818584e+00]\n",
      " [-1.94455515e+00 -3.87864962e+00]\n",
      " [ 6.96964868e-01  1.62099598e+00]\n",
      " [ 3.04346957e+00 -1.49604933e+00]\n",
      " [-2.78526750e+00  1.41174425e-01]\n",
      " [-1.24451161e+00  1.59976943e-01]\n",
      " [ 2.54265138e+00 -1.55396632e+00]\n",
      " [-5.01957267e+00 -2.40442320e+00]]\n",
      "Explained Variance: [0.08547956 0.06691276]\n",
      "[1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 2 2 0 0 0 1 0 1 0 2 2 2 2 0 1 1 1 1 1 0\n",
      " 0 2 0 2 0 2 1 0 2 0 2 1 0 1 0 0 2 1 1 0 2 2 1 1 2 0 2 0 2 0 2 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 2 1 2 1 0 2 0 1 2 2 2 2 2 0 1 2 2 0 0 0 2 1 1 2 0 0 1 0 1 2 1\n",
      " 2 2 1 1 2 2 0 1 2 1 0 2 1 2 1 0 0 2 0 1 0 1 1 1 2 1 1 2 0 0 0 2 0 0 0 1 0\n",
      " 2 1 1 1 1 1 0 2 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "model_PCA_selfmade = PCA_Selfmade(n_components=2)\n",
    "label_pca = model_PCA_selfmade.fit_transform(X_train)\n",
    "print(\"Transformed Data:\\n\", label_pca) \n",
    "print(\"Explained Variance:\", model_PCA_selfmade.explained_variance)\n",
    "\n",
    "y_pred_PCA_selfmade = kmeans.fit_predict(label_pca)\n",
    "print(y_pred_PCA_selfmade)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (Library):\n",
      " [[-6.37156472e+02  1.87967502e+02]\n",
      " [-9.36766763e+02 -1.15286540e+02]\n",
      " [-8.73073946e+02  1.27047600e+02]\n",
      " [ 2.06191396e+02 -1.69752601e+02]\n",
      " [-2.69006748e+02 -9.06967105e+01]\n",
      " [ 7.89780116e+01 -4.99300410e+00]\n",
      " [ 4.09624055e+02 -1.10677396e+02]\n",
      " [-3.23937356e+02 -2.12559521e+02]\n",
      " [-3.54204899e+02 -5.52805882e+01]\n",
      " [-2.06775951e+01  3.06145386e+02]\n",
      " [-6.71626451e+02 -1.97925606e+02]\n",
      " [ 4.10924074e+02  2.87538759e+01]\n",
      " [-9.16394919e+02 -5.52711465e+01]\n",
      " [-9.02645819e+02  6.11521805e+01]\n",
      " [-2.35993749e+02 -1.30266049e+02]\n",
      " [-6.02605061e+02 -6.97209940e+01]\n",
      " [ 8.47845755e+02 -6.44099181e+01]\n",
      " [-6.50705347e+02 -2.94498646e+01]\n",
      " [ 1.84307558e+03 -1.89899653e+02]\n",
      " [-7.78542123e+02 -1.48217640e+02]\n",
      " [-8.97011712e+02  5.50590574e-01]\n",
      " [-8.75939310e+02 -2.07531332e+02]\n",
      " [-5.92737235e+02  6.24029577e+01]\n",
      " [ 5.69312943e+02 -8.26820243e+01]\n",
      " [-4.85187518e+02  3.16806434e+02]\n",
      " [-8.66490237e+02 -1.87714236e+02]\n",
      " [-8.76828196e+02  5.13197543e+01]\n",
      " [-9.18814679e+02 -1.16408830e+02]\n",
      " [ 5.81896559e+02 -1.01233576e+02]\n",
      " [ 2.32462883e+03  4.17361510e+01]\n",
      " [-8.11621447e+02 -1.51250916e+02]\n",
      " [-3.60788703e+02  1.76506545e+02]\n",
      " [-5.03918243e+02  2.59550374e+02]\n",
      " [-6.18291026e+02  1.57763186e+02]\n",
      " [ 4.90967587e+02  2.14275639e+02]\n",
      " [ 3.05411212e+03  3.13897812e+02]\n",
      " [-8.36408664e+02 -1.49845275e+01]\n",
      " [ 1.73325518e+03 -1.18693486e+01]\n",
      " [-9.19667343e+02 -1.10078185e+02]\n",
      " [-5.05668043e+02 -1.17245709e+02]\n",
      " [-7.57057180e+02 -8.57526979e+01]\n",
      " [-7.28692162e+02  1.39296417e+01]\n",
      " [-6.09997849e+02 -1.74421277e-01]\n",
      " [-3.73178786e+02  1.26119190e+02]\n",
      " [ 2.54615415e+03  2.73599045e+02]\n",
      " [ 1.54198947e+02  4.95940632e+00]\n",
      " [ 2.85030197e+02 -6.12878805e+00]\n",
      " [-5.48247455e+02  2.39719148e+02]\n",
      " [-7.67686111e+02 -2.91989827e+01]\n",
      " [-3.97133242e+02 -2.20351083e+02]\n",
      " [ 8.72321439e+02 -4.08553203e+01]\n",
      " [ 6.90253618e+02 -2.16572354e+02]\n",
      " [-7.71836876e+02 -3.34856172e+01]\n",
      " [-8.92709928e+02 -1.12350047e+02]\n",
      " [-7.42638614e+02 -1.83155687e+01]\n",
      " [-2.24737570e+02  1.77631314e+02]\n",
      " [ 1.04443749e+03  4.60026375e+01]\n",
      " [-7.07661361e+02 -1.97067604e+02]\n",
      " [-8.30037717e+02 -2.12104419e+02]\n",
      " [ 1.65953511e+02 -1.43779719e+02]\n",
      " [-7.89613906e+02  1.91181448e+02]\n",
      " [-5.56103008e+01 -7.45540649e+01]\n",
      " [ 2.89425445e+03 -1.06707317e+02]\n",
      " [-8.01394881e+02  1.53873496e+02]\n",
      " [ 2.89438735e+03 -1.54982228e+01]\n",
      " [-4.28987385e+02 -1.70459130e+02]\n",
      " [-9.25737354e+02  9.88485221e+01]\n",
      " [-5.21326868e+02 -1.00357453e+02]\n",
      " [-7.88007411e+02  3.16722874e+01]\n",
      " [-5.95262137e+02 -5.52699247e+01]\n",
      " [-4.99064218e+02  1.63461002e+02]\n",
      " [ 6.86790582e+02 -1.47780050e+02]\n",
      " [ 2.67625926e+03 -6.05094074e+01]\n",
      " [-6.98589807e+02  5.87953769e+01]\n",
      " [-9.14312274e+02 -1.80399454e+02]\n",
      " [-6.33430788e+02 -1.02668811e+02]\n",
      " [ 6.22083234e+02 -1.77615518e+02]\n",
      " [-8.82136190e+02 -8.79249205e+01]\n",
      " [-6.87956461e+02 -2.71631983e+01]\n",
      " [ 1.97377399e+03  2.42276689e+02]\n",
      " [ 1.89310912e+02  9.04577999e+01]\n",
      " [ 4.23198308e+02  6.13578685e+01]\n",
      " [ 1.49514993e+03  2.82112988e+01]\n",
      " [-7.67151081e+02 -8.91897761e+01]\n",
      " [-3.05493391e+02 -1.50864979e+02]\n",
      " [ 1.46088687e+03 -1.52589800e+02]\n",
      " [-9.38004862e+02  2.14885123e+02]\n",
      " [-5.12454766e+02  4.33690755e+02]\n",
      " [-5.08577448e+01 -1.26516178e+02]\n",
      " [ 6.73116582e+02  1.20462919e+02]\n",
      " [ 2.49466399e+03 -1.25974977e+02]\n",
      " [-4.71557257e+02  9.82275330e+01]\n",
      " [-9.43731826e+02  1.69770243e+02]\n",
      " [-1.35020408e+02 -1.75059743e+02]\n",
      " [ 3.35030622e+02  4.86698387e+01]\n",
      " [-8.56937348e+01 -7.29042407e+01]\n",
      " [ 7.83094420e+02 -5.21980696e+01]\n",
      " [-5.76345024e+02  3.25762437e+02]\n",
      " [ 2.40270612e+03 -1.67610347e+02]\n",
      " [ 2.46353202e+03 -8.93133057e+01]\n",
      " [-4.95119525e+02 -1.33605979e+02]\n",
      " [ 9.05876927e+02  2.37939638e+01]\n",
      " [-7.22461312e+02  1.56891211e+02]\n",
      " [-8.62570019e+02 -2.27805399e+01]\n",
      " [-6.91831185e+01  1.55385858e+02]\n",
      " [-2.44127677e+02 -9.36993659e+01]\n",
      " [-5.93974834e+02 -2.00261051e+01]\n",
      " [ 2.21378341e+02  1.76237159e+02]\n",
      " [-7.43854086e+02  4.24810718e+02]\n",
      " [ 2.17842793e+03 -4.89169933e+01]\n",
      " [-6.03057157e+02 -8.70144661e+01]\n",
      " [-8.61754464e+02 -2.00606414e+02]\n",
      " [-9.15797167e+02 -1.16621388e+02]\n",
      " [-6.33101461e+02  3.76660948e+02]\n",
      " [-9.38033498e+02 -6.65435167e+01]\n",
      " [-7.88271536e+02 -9.53057304e+01]\n",
      " [ 1.57330427e+03 -1.77436497e+02]\n",
      " [ 1.69073805e+03  1.00074837e+01]\n",
      " [ 4.26837519e+02  3.35034251e+02]\n",
      " [-8.88894178e+02  1.34613091e+02]\n",
      " [-8.13889158e+02  1.39260550e+02]\n",
      " [-5.10804732e+02 -1.19589378e+02]\n",
      " [-8.88088515e+02 -1.28907412e+02]\n",
      " [ 2.15896848e+03 -1.47782983e+02]\n",
      " [-9.46630881e+02 -6.77659367e+01]\n",
      " [-8.18128546e+02  4.13220635e+01]\n",
      " [-7.93889610e+01 -2.11055387e+01]\n",
      " [ 7.62686869e+02  5.15337380e+01]\n",
      " [ 1.55419127e+02  1.38544377e+02]\n",
      " [ 6.69223150e+02  1.25162523e+02]\n",
      " [-6.04672310e+02  1.00511069e+02]\n",
      " [-5.38822981e+02  4.86226147e+01]\n",
      " [-2.53643387e+02 -1.07322660e+02]\n",
      " [-6.35996748e+02 -9.79767171e+01]\n",
      " [ 6.97692738e+02 -6.59495908e+01]\n",
      " [-4.84101914e+02 -1.32881277e+02]\n",
      " [ 2.87310297e+02 -7.90305647e+01]\n",
      " [ 5.89635430e+02  1.89672892e+01]\n",
      " [-8.33913234e+02  3.02180905e+02]\n",
      " [-8.73242866e+02 -9.89779562e+00]\n",
      " [ 1.13724319e+00 -1.72425859e+02]\n",
      " [-1.06487417e+01 -7.20897151e+01]\n",
      " [-8.50808680e+02  1.08659050e+01]\n",
      " [-6.37349089e+02 -1.61808058e+01]\n",
      " [-6.87693732e+02 -3.07582417e+01]\n",
      " [ 2.72681699e+03 -1.64472300e+02]\n",
      " [-6.45183314e+02 -4.85780452e+01]\n",
      " [-9.45400848e+02 -1.00582239e+02]\n",
      " [-3.65963758e+02 -1.71813917e+02]\n",
      " [ 2.90205193e+02  1.30131401e+02]\n",
      " [ 2.80784995e+03  9.33667809e+01]\n",
      " [-8.03308605e+02  1.59542917e+02]\n",
      " [-7.63377137e+02  1.97254214e+02]\n",
      " [ 7.98179404e+02  3.96417455e+02]\n",
      " [ 2.42452727e+03 -4.86116375e+01]\n",
      " [-5.67861534e+02 -1.22266054e+02]\n",
      " [-3.60033145e+02 -1.28108004e+02]\n",
      " [-6.78917940e+02 -1.22763920e+02]\n",
      " [ 1.90341780e+03  2.49436173e+02]\n",
      " [-4.86897736e+02  9.40933488e+01]]\n",
      "Explained Variance (Library): [0.970906   0.02005153]\n",
      "[1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 2 1 1 1 1 0 1 1 1 1 0 2 1 1 1 1 0 2 1\n",
      " 2 1 1 1 1 1 1 2 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 2 1 2 1 1 1 1 1 1 0 2 1\n",
      " 1 1 0 1 1 2 0 0 2 1 1 2 1 1 0 0 2 1 1 1 0 0 0 1 2 2 1 0 1 1 0 1 1 0 1 2 1\n",
      " 1 1 1 1 1 2 2 0 1 1 1 1 2 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 2 1 1\n",
      " 1 0 2 1 1 0 2 1 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "model_PCA_library = PCA(n_components=2)\n",
    "label_pca_library = model_PCA_library.fit_transform(X_train)\n",
    "\n",
    "print(\"Transformed Data (Library):\\n\", label_pca_library)\n",
    "print(\"Explained Variance (Library):\", model_PCA_library.explained_variance_ratio_)\n",
    "\n",
    "y_pred_PCA_library = kmeans.fit_predict(label_pca_library)\n",
    "print(y_pred_PCA_library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.42      0.33        40\n",
      "           1       0.65      0.35      0.45        98\n",
      "           2       0.18      0.36      0.24        22\n",
      "\n",
      "    accuracy                           0.37       160\n",
      "   macro avg       0.37      0.38      0.34       160\n",
      "weighted avg       0.49      0.37      0.39       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_PCA_library, y_pred_PCA_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        23\n",
      "           1       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.82      0.82      0.82        40\n",
      "weighted avg       0.83      0.82      0.83        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_bagging_selfmade = Ensemble_Bagging_Selfmade(base_estimator=DecisionTreeClassifier, n_estimators=5, max_samples=0.6)\n",
    "\n",
    "model_bagging_selfmade.fit(X_train, y_train)\n",
    "y_pred_bagging_selfmade = model_bagging_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_bagging_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
