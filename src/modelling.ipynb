{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Selfmade\n",
    "from KNN_Selfmade import KNN_Selfmade\n",
    "from Logistic_Regression_Selfmade import Logistic_Regression_Selfmade\n",
    "from Gaussian_Naive_Bayes_Selfmade import Gaussian_Naive_Bayes_Selfmade\n",
    "from CART_Selfmade import CART_Selfmade\n",
    "from SVM_Selfmade import SVC_Selfmade\n",
    "from ANN_Selfmade import ANN_Selfmade\n",
    "from KMeans_Cluster_Selfmade import KMeans_Selfmade\n",
    "from DBSCAN_Selfmade import DBSCAN_Selfmade\n",
    "from PCA_Selfmade import PCA_Selfmade\n",
    "from Ensemble_Bagging_Selfmade import Ensemble_Bagging_Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_df = pd.read_csv(\"../dataset/subsampled_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subsampled_df.drop(columns='deposit')\n",
    "y = subsampled_df['deposit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      5757\n",
      "           1       0.39      0.12      0.18       537\n",
      "\n",
      "    accuracy                           0.91      6294\n",
      "   macro avg       0.66      0.55      0.57      6294\n",
      "weighted avg       0.88      0.91      0.89      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn_selfmade = KNN_Selfmade(neighbors=7, metric='euclidean')\n",
    "model_knn_selfmade.fit(X_train, y_train)\n",
    "y_pred_knn_selfmade = model_knn_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_knn_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      5757\n",
      "           1       0.45      0.14      0.22       537\n",
      "\n",
      "    accuracy                           0.91      6294\n",
      "   macro avg       0.69      0.56      0.58      6294\n",
      "weighted avg       0.88      0.91      0.89      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn_library = KNeighborsClassifier(n_neighbors=7, metric='manhattan')\n",
    "model_knn_library.fit(X_train, y_train)\n",
    "y_pred_knn_library = model_knn_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_knn_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986495074674293\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_knn_selfmade == y_pred_knn_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599453\n",
      "Iteration 100, Loss: 1.4212618613019445\n",
      "Iteration 200, Loss: 1.5332447147530426\n",
      "Iteration 300, Loss: 7.696789596601651\n",
      "Iteration 400, Loss: 1.4253936000381593\n",
      "Iteration 500, Loss: 10.575828108074568\n",
      "Iteration 600, Loss: 1.38666008661083\n",
      "Iteration 700, Loss: 1.3783174837188952\n",
      "Iteration 800, Loss: 1.4239339739118122\n",
      "Iteration 900, Loss: 1.3783174837188952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.96      6289\n",
      "           1       0.00      0.40      0.01         5\n",
      "\n",
      "    accuracy                           0.91      6294\n",
      "   macro avg       0.50      0.66      0.48      6294\n",
      "weighted avg       1.00      0.91      0.95      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_selfmade = Logistic_Regression_Selfmade(learning_rate=0.5, n_iterations=1000, regularization='l1', reg_lambda=0.01, loss_function='cross_entropy')\n",
    "model_log_reg_selfmade.fit(X_train, y_train)\n",
    "y_pred_log_reg_selfmade = model_log_reg_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_log_reg_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      6133\n",
      "           1       0.15      0.52      0.24       161\n",
      "\n",
      "    accuracy                           0.92      6294\n",
      "   macro avg       0.57      0.72      0.60      6294\n",
      "weighted avg       0.97      0.92      0.94      6294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_library = LogisticRegression(max_iter=100, C=1/0.1, penalty='l2')\n",
    "model_log_reg_library.fit(X_train, y_train)\n",
    "y_pred_log_reg_library = model_log_reg_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_log_reg_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736256752462663\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_log_reg_selfmade == y_pred_log_reg_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      5349\n",
      "           1       0.60      0.34      0.43       945\n",
      "\n",
      "    accuracy                           0.87      6294\n",
      "   macro avg       0.74      0.65      0.68      6294\n",
      "weighted avg       0.85      0.87      0.85      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_naive_bayes_selfmade = Gaussian_Naive_Bayes_Selfmade()\n",
    "model_naive_bayes_selfmade.fit(X_train, y_train)\n",
    "y_pred_naive_bayes_selfmade = model_naive_bayes_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_naive_bayes_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      5345\n",
      "           1       0.60      0.34      0.44       949\n",
      "\n",
      "    accuracy                           0.87      6294\n",
      "   macro avg       0.75      0.65      0.68      6294\n",
      "weighted avg       0.85      0.87      0.85      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_naive_bayes_library = GaussianNB()\n",
    "model_naive_bayes_library.fit(X_train, y_train)\n",
    "y_pred_naive_bayes_library = model_naive_bayes_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_naive_bayes_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9971401334604385\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_naive_bayes_selfmade == y_pred_naive_bayes_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      6150\n",
      "           1       0.20      0.76      0.32       144\n",
      "\n",
      "    accuracy                           0.93      6294\n",
      "   macro avg       0.60      0.84      0.64      6294\n",
      "weighted avg       0.98      0.93      0.95      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_CART_selfmade = CART_Selfmade(max_depth=3)\n",
    "model_CART_selfmade.fit(X_train, y_train)\n",
    "y_pred_CART_selfmade = model_CART_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_CART_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      6150\n",
      "           1       0.20      0.76      0.32       144\n",
      "\n",
      "    accuracy                           0.93      6294\n",
      "   macro avg       0.60      0.84      0.64      6294\n",
      "weighted avg       0.98      0.93      0.95      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_CART_library = DecisionTreeClassifier(max_depth=3)\n",
    "model_CART_library.fit(X_train, y_train)\n",
    "y_pred_CART_library = model_CART_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_CART_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_CART_selfmade == y_pred_CART_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00    6294.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    6294.0\n",
      "   macro avg       0.00      0.00      0.00    6294.0\n",
      "weighted avg       0.00      0.00      0.00    6294.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_SVC_selfmade = SVC_Selfmade(learning_rate=0.01, lambda_param=0.01, n_iters=100, kernel='linear')\n",
    "model_SVC_selfmade.fit(X_train.values, y_train.values)\n",
    "y_pred_SVC_selfmade = model_SVC_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_SVC_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.88      0.38      1575\n",
      "           1       0.64      0.07      0.13      4719\n",
      "\n",
      "    accuracy                           0.27      6294\n",
      "   macro avg       0.44      0.47      0.25      6294\n",
      "weighted avg       0.54      0.27      0.19      6294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_SVC_library = SVC(max_iter=100, kernel='linear')\n",
    "model_SVC_library.fit(X_train.values, y_train.values)\n",
    "y_pred_SVC_library = model_SVC_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_SVC_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_pred_SVC_selfmade == y_pred_SVC_library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ANN_selfmade = ANN_Selfmade(sizes=[51, 50, 1], activation='sigmoid')\n",
    "# model_ANN_selfmade.train(X_train.to_numpy(), y_train.to_numpy(), X_test.to_numpy(), y_test.to_numpy(), batch_size=20, optimizer='sgd', l_rate=0.0001, beta=.9)\n",
    "# y_pred_ANN_selfmade = model_ANN_selfmade.predict()\n",
    "\n",
    "# print(classification_report(y_pred_ANN_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.96      6294\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91      6294\n",
      "   macro avg       0.50      0.46      0.48      6294\n",
      "weighted avg       1.00      0.91      0.96      6294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_ANN_library = MLPClassifier(hidden_layer_sizes=(50,), activation='logistic', solver='sgd',\n",
    "                    learning_rate_init=0.0001, max_iter=10, batch_size=20, momentum=0.9)\n",
    "model_ANN_library.fit(X_train, y_train)\n",
    "y_pred_ANN_library = model_ANN_library.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_ANN_library, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "model_KMeans_selfmade = KMeans_Selfmade(n_clusters=2, max_iter=100)\n",
    "model_KMeans_selfmade.fit(X_train)\n",
    "y_pred_KMeans_selfmade = model_KMeans_selfmade.predict(X_test)\n",
    "\n",
    "print(y_pred_KMeans_selfmade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_KMeans_library = KMeans(n_clusters=2, max_iter=100)\n",
    "model_KMeans_library.fit(X_train)\n",
    "y_pred_KMeans_library = model_KMeans_library.predict(X_test)\n",
    "\n",
    "print(y_pred_KMeans_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    4967.0\n",
      "           1       0.00      0.00      0.00    1327.0\n",
      "\n",
      "    accuracy                           0.00    6294.0\n",
      "   macro avg       0.00      0.00      0.00    6294.0\n",
      "weighted avg       0.00      0.00      0.00    6294.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_KMeans_library, y_pred_KMeans_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Selfmade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  0 ... 13 75  1]\n"
     ]
    }
   ],
   "source": [
    "model_DBSCAN_selfmade = DBSCAN_Selfmade(eps=200, min_samples=3, metric='euclidean', p=5)\n",
    "model_DBSCAN_selfmade.fit(X_train)\n",
    "y_pred_DBSCAN_selfmade = model_DBSCAN_selfmade.predict()\n",
    "\n",
    "print(y_pred_DBSCAN_selfmade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_DBSCAN_library = DBSCAN(eps=200, min_samples=3).fit(X_train)\n",
    "y_pred_DBSCAN_library = model_DBSCAN_library.labels_\n",
    "\n",
    "print(y_pred_DBSCAN_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      1.00      0.80         8\n",
      "           0       1.00      0.16      0.28     25164\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         0\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.00      0.00      0.00         0\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.00      0.00      0.00         0\n",
      "         129       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17     25172\n",
      "   macro avg       0.01      0.01      0.01     25172\n",
      "weighted avg       1.00      0.17      0.28     25172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_DBSCAN_library, y_pred_DBSCAN_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data:\n",
      " [[ 1.71816803e-01 -2.92513393e+00]\n",
      " [-3.51052896e-01 -8.38781739e-01]\n",
      " [ 1.87254594e+00  1.88551110e+00]\n",
      " ...\n",
      " [-4.98992492e-03 -1.70346875e+00]\n",
      " [ 3.34779199e-01  1.06595711e-03]\n",
      " [-9.09152723e-01 -1.02063245e+00]]\n",
      "Explained Variance: [0.07276258 0.0642876 ]\n",
      "[0 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "model_PCA_selfmade = PCA_Selfmade(n_components=2)\n",
    "label_pca = model_PCA_selfmade.fit_transform(X_train)\n",
    "print(\"Transformed Data:\\n\", label_pca) \n",
    "print(\"Explained Variance:\", model_PCA_selfmade.explained_variance)\n",
    "\n",
    "y_pred_PCA_selfmade = kmeans.fit_predict(label_pca)\n",
    "print(y_pred_PCA_selfmade)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (Library):\n",
      " [[-508.04679324 -121.36759196]\n",
      " [-866.01820312 -111.79415467]\n",
      " [-592.63864497  -17.9766803 ]\n",
      " ...\n",
      " [-228.06263749 -120.40551488]\n",
      " [ -97.15186143  330.71865728]\n",
      " [-760.9520981   -92.16969219]]\n",
      "Explained Variance (Library): [0.96623848 0.02197796]\n",
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "model_PCA_library = PCA(n_components=2)\n",
    "label_pca_library = model_PCA_library.fit_transform(X_train)\n",
    "\n",
    "print(\"Transformed Data (Library):\\n\", label_pca_library)\n",
    "print(\"Explained Variance (Library):\", model_PCA_library.explained_variance_ratio_)\n",
    "\n",
    "y_pred_PCA_library = kmeans.fit_predict(label_pca_library)\n",
    "print(y_pred_PCA_library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.41      0.31      6124\n",
      "           1       0.10      0.33      0.15      2968\n",
      "           2       0.60      0.17      0.27     16080\n",
      "\n",
      "    accuracy                           0.25     25172\n",
      "   macro avg       0.31      0.31      0.24     25172\n",
      "weighted avg       0.45      0.25      0.26     25172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_PCA_library, y_pred_PCA_selfmade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82        27\n",
      "           1       0.61      0.85      0.71        13\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.76      0.79      0.76        40\n",
      "weighted avg       0.81      0.78      0.78        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_bagging_selfmade = Ensemble_Bagging_Selfmade(base_estimator=DecisionTreeClassifier, n_estimators=5, max_samples=0.6)\n",
    "\n",
    "model_bagging_selfmade.fit(X_train, y_train)\n",
    "y_pred_bagging_selfmade = model_bagging_selfmade.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred_bagging_selfmade, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
